#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ£€ç´¢åˆ†æ•°è°ƒè¯•å·¥å…·
ç”¨äºæŸ¥çœ‹æ‰€æœ‰æ£€ç´¢åˆ°çš„æ–‡æ¡£åŠå…¶åˆ†æ•°ï¼Œå¸®åŠ©è°ƒè¯•ä¸ºä»€ä¹ˆæŸäº›æ–‡æ¡£æ²¡æœ‰è¢«æ£€ç´¢åˆ°
"""
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

from config import Settings
from llama_index.core import QueryBundle, load_index_from_storage, StorageContext
from llama_index.core.postprocessor import SentenceTransformerRerank
from llama_index.vector_stores.qdrant import QdrantVectorStore
from qdrant_client import QdrantClient
from core.retriever import HybridRetriever
from utils import logger
import logging

# è®¾ç½®æ—¥å¿—çº§åˆ«ä¸º INFO
logging.basicConfig(level=logging.INFO)


def _init_retriever():
    """åˆå§‹åŒ–æ£€ç´¢å™¨å’Œé‡æ’åºå™¨"""
    # åˆå§‹åŒ– Qdrant å®¢æˆ·ç«¯
    qdrant_client = QdrantClient(
        host=Settings.QDRANT_HOST,
        port=Settings.QDRANT_PORT
    )
    
    # åŠ è½½å‘é‡å­˜å‚¨
    vector_store = QdrantVectorStore(
        client=qdrant_client,
        collection_name=Settings.QDRANT_COLLECTION
    )
    
    # åŠ è½½ç´¢å¼•
    storage_context = StorageContext.from_defaults(
        vector_store=vector_store,
        persist_dir=Settings.STORAGE_PATH
    )
    index = load_index_from_storage(storage_context)
    
    # åˆ›å»ºæ··åˆæ£€ç´¢å™¨
    retriever = HybridRetriever(
        index=index,
        vector_top_k=Settings.RETRIEVAL_TOP_K,
        bm25_top_k=Settings.RETRIEVAL_TOP_K_BM25,
        rrf_k=Settings.RRF_K,
        vector_weight=Settings.RRF_VECTOR_WEIGHT,
        bm25_weight=Settings.RRF_BM25_WEIGHT
    )
    
    # åˆ›å»ºé‡æ’åºå™¨
    reranker = SentenceTransformerRerank(
        model=Settings.RERANKER_MODEL_PATH,
        top_n=Settings.RERANK_TOP_N,
        device=Settings.DEVICE
    )
    
    return retriever, reranker


def debug_retrieval(question: str, top_k: int = 50, show_subquestions: bool = False):
    """
    è°ƒè¯•æ£€ç´¢è¿‡ç¨‹ï¼Œæ˜¾ç¤ºæ‰€æœ‰æ£€ç´¢åˆ°çš„æ–‡æ¡£åŠå…¶åˆ†æ•°
    
    Args:
        question: ç”¨æˆ·é—®é¢˜
        top_k: æ˜¾ç¤ºå‰ N ä¸ªç»“æœï¼ˆé»˜è®¤50ï¼‰
        show_subquestions: æ˜¯å¦æ˜¾ç¤ºå­é—®é¢˜åˆ†è§£ä¿¡æ¯
    """
    print("=" * 80)
    print(f"ğŸ” æ£€ç´¢è°ƒè¯•å·¥å…·")
    print(f"é—®é¢˜: {question}")
    print(f"æ˜¾ç¤ºå‰ {top_k} ä¸ªç»“æœ")
    if show_subquestions:
        print(f"å­é—®é¢˜åˆ†è§£: å¯ç”¨")
    print("=" * 80)
    
    # åˆå§‹åŒ–æ£€ç´¢å™¨
    retriever, reranker = _init_retriever()
    
    print("\nğŸ“Š ç¬¬ä¸€æ­¥ï¼šå‘é‡æ£€ç´¢ + BM25 æ£€ç´¢ï¼ˆæ··åˆæ£€ç´¢ï¼‰")
    print("-" * 80)
    
    # æ‰§è¡Œæ£€ç´¢
    retrieved_nodes = retriever.retrieve(question)
    
    print(f"âœ“ åˆå§‹æ£€ç´¢åˆ° {len(retrieved_nodes)} ä¸ªèŠ‚ç‚¹")
    print("\nå‰ {} ä¸ªèŠ‚ç‚¹çš„è¯¦ç»†ä¿¡æ¯ï¼š\n".format(min(top_k, len(retrieved_nodes))))
    
    # æ˜¾ç¤ºåˆå§‹æ£€ç´¢ç»“æœ
    for i, node in enumerate(retrieved_nodes[:top_k], 1):
        file_name = node.node.metadata.get('file_name', 'æœªçŸ¥')
        score = node.score
        
        # æå–æ£€ç´¢å…ƒæ•°æ®
        retrieval_sources = node.node.metadata.get('retrieval_sources', [])
        vector_score = node.node.metadata.get('vector_score', 0.0)
        bm25_score = node.node.metadata.get('bm25_score', 0.0)
        vector_rank = node.node.metadata.get('vector_rank', '-')
        bm25_rank = node.node.metadata.get('bm25_rank', '-')
        matched_keywords = node.node.metadata.get('bm25_matched_keywords', [])
        
        # å­é—®é¢˜åˆ†è§£å…ƒæ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
        sub_question = node.node.metadata.get('sub_question', None)
        
        # è·å–å†…å®¹é¢„è§ˆ
        content = node.node.get_content()
        content_preview = content[:100].replace('\n', ' ') + '...' if len(content) > 100 else content
        
        # æ ¼å¼åŒ–è¾“å‡º
        sources_str = '+'.join(retrieval_sources) if retrieval_sources else 'æœªçŸ¥'
        
        print(f"[{i:2d}] {file_name}")
        print(f"     RRFèåˆåˆ†æ•°: {score:.6f}")
        print(f"     æ£€ç´¢æ¥æº: {sources_str}")
        
        if 'vector' in retrieval_sources:
            print(f"       - å‘é‡åˆ†æ•°: {vector_score:.6f} (æ’å #{vector_rank})")
        if 'keyword' in retrieval_sources:
            print(f"       - BM25åˆ†æ•°: {bm25_score:.6f} (æ’å #{bm25_rank})")
            if matched_keywords:
                print(f"       - åŒ¹é…å…³é”®è¯: {', '.join(matched_keywords)}")
        
        # æ˜¾ç¤ºå­é—®é¢˜ä¿¡æ¯
        if show_subquestions and sub_question:
            print(f"     ğŸ”— å­é—®é¢˜: {sub_question}")
        
        print(f"     å†…å®¹é¢„è§ˆ: {content_preview}")
        print()
    
    # é‡æ’åº
    print("\nğŸ“Š ç¬¬äºŒæ­¥ï¼šé‡æ’åºï¼ˆRerankerï¼‰")
    print("-" * 80)
    
    # å–å‰ N ä¸ªé€å…¥é‡æ’
    reranker_input_top_n = Settings.RERANKER_INPUT_TOP_N
    reranker_input = retrieved_nodes[:reranker_input_top_n]
    
    print(f"âœ“ å–å‰ {len(reranker_input)} ä¸ªèŠ‚ç‚¹é€å…¥é‡æ’åº")
    
    if reranker_input:
        reranked_nodes = reranker.postprocess_nodes(
            reranker_input,
            query_bundle=QueryBundle(question)
        )
        
        print(f"âœ“ é‡æ’åºå®Œæˆï¼Œå¾—åˆ° {len(reranked_nodes)} ä¸ªèŠ‚ç‚¹")
        print(f"\nå‰ {min(20, len(reranked_nodes))} ä¸ªé‡æ’åºåçš„èŠ‚ç‚¹ï¼š\n")
        
        for i, node in enumerate(reranked_nodes[:20], 1):
            file_name = node.node.metadata.get('file_name', 'æœªçŸ¥')
            initial_score = node.node.metadata.get('initial_score', 0.0)
            rerank_score = node.score
            
            content = node.node.get_content()
            content_preview = content[:100].replace('\n', ' ') + '...' if len(content) > 100 else content
            
            print(f"[{i:2d}] {file_name}")
            print(f"     åˆå§‹åˆ†æ•°: {initial_score:.6f} â†’ é‡æ’åˆ†æ•°: {rerank_score:.6f}")
            print(f"     å†…å®¹é¢„è§ˆ: {content_preview}")
            print()
    
    # é˜ˆå€¼è¿‡æ»¤
    print("\nğŸ“Š ç¬¬ä¸‰æ­¥ï¼šé˜ˆå€¼è¿‡æ»¤")
    print("-" * 80)
    
    threshold = Settings.RERANK_SCORE_THRESHOLD
    print(f"é˜ˆå€¼è®¾ç½®: {threshold}")
    
    final_nodes = [
        node for node in reranked_nodes
        if node.score >= threshold
    ]
    
    print(f"âœ“ ç»è¿‡é˜ˆå€¼è¿‡æ»¤åå‰©ä½™ {len(final_nodes)} ä¸ªèŠ‚ç‚¹")
    
    if len(final_nodes) == 0 and len(reranked_nodes) > 0:
        max_score = max(node.score for node in reranked_nodes)
        print(f"\nâš ï¸ è­¦å‘Šï¼šæ‰€æœ‰èŠ‚ç‚¹éƒ½è¢«é˜ˆå€¼è¿‡æ»¤æ‰äº†ï¼")
        print(f"   æœ€é«˜åˆ†æ•°: {max_score:.6f}")
        print(f"   å½“å‰é˜ˆå€¼: {threshold}")
        print(f"   å»ºè®®ï¼šé™ä½ RERANK_SCORE_THRESHOLD é…ç½®")
    
    print("\n" + "=" * 80)
    print("ğŸ¯ è°ƒè¯•æ€»ç»“")
    print("=" * 80)
    print(f"åˆå§‹æ£€ç´¢: {len(retrieved_nodes)} ä¸ªèŠ‚ç‚¹")
    print(f"é‡æ’åºè¾“å…¥: {len(reranker_input)} ä¸ªèŠ‚ç‚¹")
    print(f"é‡æ’åºè¾“å‡º: {len(reranked_nodes)} ä¸ªèŠ‚ç‚¹")
    print(f"é˜ˆå€¼è¿‡æ»¤å: {len(final_nodes)} ä¸ªèŠ‚ç‚¹")
    print("=" * 80)
    
    # ç»Ÿè®¡æ–‡ä»¶åˆ†å¸ƒ
    print("\nğŸ“ æ–‡ä»¶åˆ†å¸ƒç»Ÿè®¡")
    print("-" * 80)
    
    file_stats = {}
    for node in retrieved_nodes[:top_k]:
        file_name = node.node.metadata.get('file_name', 'æœªçŸ¥')
        file_stats[file_name] = file_stats.get(file_name, 0) + 1
    
    for file_name, count in sorted(file_stats.items(), key=lambda x: x[1], reverse=True):
        print(f"  {file_name}: {count} ä¸ªèŠ‚ç‚¹")
    
    # å­é—®é¢˜åˆ†è§£ç»Ÿè®¡
    if show_subquestions:
        print("\nğŸ”— å­é—®é¢˜åˆ†è§£ç»Ÿè®¡")
        print("-" * 80)
        
        subq_stats = {}
        for node in retrieved_nodes[:top_k]:
            sub_question = node.node.metadata.get('sub_question', None)
            if sub_question:
                subq_stats[sub_question] = subq_stats.get(sub_question, 0) + 1
        
        if subq_stats:
            print(f"æ£€æµ‹åˆ° {len(subq_stats)} ä¸ªå­é—®é¢˜ï¼š")
            for i, (sub_q, count) in enumerate(subq_stats.items(), 1):
                print(f"  å­é—®é¢˜{i}: {sub_q}")
                print(f"    â†’ åŒ¹é…èŠ‚ç‚¹æ•°: {count}")
        else:
            print("  æœªæ£€æµ‹åˆ°å­é—®é¢˜åˆ†è§£ï¼ˆå¯èƒ½æœªå¯ç”¨æˆ–æœªè§¦å‘ï¼‰")
    
    print("\n" + "=" * 80)


def search_specific_file(question: str, target_file: str, top_k: int = 100):
    """
    æœç´¢ç‰¹å®šæ–‡ä»¶åœ¨æ£€ç´¢ç»“æœä¸­çš„ä½ç½®å’Œåˆ†æ•°
    
    Args:
        question: ç”¨æˆ·é—®é¢˜
        target_file: ç›®æ ‡æ–‡ä»¶åï¼ˆå¦‚ "æ—å…çŸ¥è¯†åº“.docx"ï¼‰
        top_k: æœç´¢å‰ N ä¸ªç»“æœ
    """
    print("=" * 80)
    print(f"ğŸ¯ æœç´¢ç‰¹å®šæ–‡ä»¶")
    print(f"é—®é¢˜: {question}")
    print(f"ç›®æ ‡æ–‡ä»¶: {target_file}")
    print("=" * 80)
    
    # åˆå§‹åŒ–æ£€ç´¢å™¨
    retriever, _ = _init_retriever()
    
    # æ‰§è¡Œæ£€ç´¢
    retrieved_nodes = retriever.retrieve(question)
    
    print(f"\nâœ“ åˆå§‹æ£€ç´¢åˆ° {len(retrieved_nodes)} ä¸ªèŠ‚ç‚¹")
    print(f"æœç´¢å‰ {min(top_k, len(retrieved_nodes))} ä¸ªç»“æœ...\n")
    
    found_nodes = []
    
    for i, node in enumerate(retrieved_nodes[:top_k], 1):
        file_name = node.node.metadata.get('file_name', 'æœªçŸ¥')
        
        if target_file in file_name or file_name in target_file:
            score = node.score
            retrieval_sources = node.node.metadata.get('retrieval_sources', [])
            vector_score = node.node.metadata.get('vector_score', 0.0)
            bm25_score = node.node.metadata.get('bm25_score', 0.0)
            
            content = node.node.get_content()
            content_preview = content[:150].replace('\n', ' ') + '...' if len(content) > 150 else content
            
            found_nodes.append({
                'rank': i,
                'file_name': file_name,
                'score': score,
                'sources': retrieval_sources,
                'vector_score': vector_score,
                'bm25_score': bm25_score,
                'content_preview': content_preview
            })
    
    if found_nodes:
        print(f"âœ… æ‰¾åˆ° {len(found_nodes)} ä¸ªæ¥è‡ª '{target_file}' çš„èŠ‚ç‚¹ï¼š\n")
        
        for node_info in found_nodes:
            print(f"æ’å #{node_info['rank']}")
            print(f"  æ–‡ä»¶: {node_info['file_name']}")
            print(f"  RRFåˆ†æ•°: {node_info['score']:.6f}")
            print(f"  æ£€ç´¢æ¥æº: {'+'.join(node_info['sources'])}")
            print(f"  å‘é‡åˆ†æ•°: {node_info['vector_score']:.6f}")
            print(f"  BM25åˆ†æ•°: {node_info['bm25_score']:.6f}")
            print(f"  å†…å®¹: {node_info['content_preview']}")
            print()
    else:
        print(f"âŒ åœ¨å‰ {min(top_k, len(retrieved_nodes))} ä¸ªç»“æœä¸­æœªæ‰¾åˆ° '{target_file}'")
        print(f"\nå¯èƒ½åŸå› ï¼š")
        print(f"  1. è¯¥æ–‡ä»¶ä¸é—®é¢˜ç›¸å…³æ€§å¤ªä½")
        print(f"  2. è¯¥æ–‡ä»¶ä¸åœ¨çŸ¥è¯†åº“ä¸­")
        print(f"  3. è¯¥æ–‡ä»¶åœ¨ {top_k} åä¹‹å")
        print(f"\nå»ºè®®ï¼š")
        print(f"  - å¢åŠ  top_k å‚æ•°ï¼ˆå¦‚ top_k=200ï¼‰")
        print(f"  - æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²åŠ è½½åˆ°çŸ¥è¯†åº“")
        print(f"  - è°ƒæ•´é—®é¢˜æè¿°ï¼Œä½¿ç”¨æ–‡ä»¶ä¸­çš„å…³é”®è¯")
    
    print("\n" + "=" * 80)


def search_text_fragment(question: str, text_fragment: str, top_k: int = 100):
    """
    æœç´¢åŒ…å«ç‰¹å®šæ–‡æœ¬ç‰‡æ®µçš„èŠ‚ç‚¹
    
    Args:
        question: ç”¨æˆ·é—®é¢˜
        text_fragment: è¦æœç´¢çš„æ–‡æœ¬ç‰‡æ®µ
        top_k: æœç´¢å‰ N ä¸ªç»“æœ
    """
    print("=" * 80)
    print(f"ğŸ” æœç´¢æ–‡æœ¬ç‰‡æ®µ")
    print(f"é—®é¢˜: {question}")
    print(f"æ–‡æœ¬ç‰‡æ®µ: {text_fragment[:50]}..." if len(text_fragment) > 50 else f"æ–‡æœ¬ç‰‡æ®µ: {text_fragment}")
    print("=" * 80)
    
    # åˆå§‹åŒ–æ£€ç´¢å™¨
    retriever, _ = _init_retriever()
    
    # æ‰§è¡Œæ£€ç´¢
    retrieved_nodes = retriever.retrieve(question)
    
    print(f"\nâœ“ åˆå§‹æ£€ç´¢åˆ° {len(retrieved_nodes)} ä¸ªèŠ‚ç‚¹")
    print(f"æœç´¢å‰ {min(top_k, len(retrieved_nodes))} ä¸ªç»“æœä¸­åŒ…å«è¯¥æ–‡æœ¬çš„èŠ‚ç‚¹...\n")
    
    found_nodes = []
    
    for i, node in enumerate(retrieved_nodes[:top_k], 1):
        content = node.node.get_content()
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«è¯¥æ–‡æœ¬ç‰‡æ®µ
        if text_fragment in content:
            file_name = node.node.metadata.get('file_name', 'æœªçŸ¥')
            score = node.score
            retrieval_sources = node.node.metadata.get('retrieval_sources', [])
            vector_score = node.node.metadata.get('vector_score', 0.0)
            bm25_score = node.node.metadata.get('bm25_score', 0.0)
            vector_rank = node.node.metadata.get('vector_rank', '-')
            bm25_rank = node.node.metadata.get('bm25_rank', '-')
            matched_keywords = node.node.metadata.get('bm25_matched_keywords', [])
            
            # æ‰¾åˆ°æ–‡æœ¬ç‰‡æ®µçš„ä½ç½®ï¼Œæ˜¾ç¤ºä¸Šä¸‹æ–‡
            start_pos = content.find(text_fragment)
            context_start = max(0, start_pos - 50)
            context_end = min(len(content), start_pos + len(text_fragment) + 50)
            context = content[context_start:context_end]
            
            found_nodes.append({
                'rank': i,
                'file_name': file_name,
                'score': score,
                'sources': retrieval_sources,
                'vector_score': vector_score,
                'bm25_score': bm25_score,
                'vector_rank': vector_rank,
                'bm25_rank': bm25_rank,
                'matched_keywords': matched_keywords,
                'context': context,
                'full_content': content
            })
    
    if found_nodes:
        print(f"âœ… æ‰¾åˆ° {len(found_nodes)} ä¸ªåŒ…å«è¯¥æ–‡æœ¬çš„èŠ‚ç‚¹ï¼š\n")
        
        for node_info in found_nodes:
            print(f"{'='*80}")
            print(f"æ’å #{node_info['rank']}")
            print(f"æ–‡ä»¶: {node_info['file_name']}")
            print(f"RRFèåˆåˆ†æ•°: {node_info['score']:.6f}")
            print(f"æ£€ç´¢æ¥æº: {'+'.join(node_info['sources']) if node_info['sources'] else 'æœªçŸ¥'}")
            
            if 'vector' in node_info['sources']:
                print(f"  - å‘é‡åˆ†æ•°: {node_info['vector_score']:.6f} (æ’å #{node_info['vector_rank']})")
            if 'keyword' in node_info['sources']:
                print(f"  - BM25åˆ†æ•°: {node_info['bm25_score']:.6f} (æ’å #{node_info['bm25_rank']})")
                if node_info['matched_keywords']:
                    print(f"  - åŒ¹é…å…³é”®è¯: {', '.join(node_info['matched_keywords'])}")
            
            print(f"\nä¸Šä¸‹æ–‡é¢„è§ˆ:")
            print(f"  ...{node_info['context']}...")
            
            print(f"\nå®Œæ•´å†…å®¹ ({len(node_info['full_content'])} å­—ç¬¦):")
            print(f"  {node_info['full_content'][:300]}...")
            print()
    else:
        print(f"âŒ åœ¨å‰ {min(top_k, len(retrieved_nodes))} ä¸ªç»“æœä¸­æœªæ‰¾åˆ°åŒ…å«è¯¥æ–‡æœ¬çš„èŠ‚ç‚¹")
        print(f"\nå¯èƒ½åŸå› ï¼š")
        print(f"  1. è¯¥æ–‡æœ¬ä¸åœ¨çŸ¥è¯†åº“ä¸­")
        print(f"  2. è¯¥æ–‡æœ¬åœ¨ {top_k} åä¹‹å")
        print(f"  3. æ–‡æœ¬å†…å®¹æœ‰ç»†å¾®å·®å¼‚ï¼ˆå¦‚ç©ºæ ¼ã€æ¢è¡Œã€æ ‡ç‚¹ï¼‰")
        print(f"\nå»ºè®®ï¼š")
        print(f"  - å¢åŠ  --top-k å‚æ•°ï¼ˆå¦‚ --top-k 200ï¼‰")
        print(f"  - å°è¯•æœç´¢æ›´çŸ­çš„å…³é”®æ–‡æœ¬ç‰‡æ®µ")
        print(f"  - ä½¿ç”¨ --file å‚æ•°æŒ‡å®šæ–‡ä»¶å")
    
    print("\n" + "=" * 80)


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='æ£€ç´¢åˆ†æ•°è°ƒè¯•å·¥å…·')
    parser.add_argument('question', type=str, help='ç”¨æˆ·é—®é¢˜')
    parser.add_argument('--top-k', type=int, default=50, help='æ˜¾ç¤ºå‰ N ä¸ªç»“æœï¼ˆé»˜è®¤50ï¼‰')
    parser.add_argument('--file', type=str, help='æœç´¢ç‰¹å®šæ–‡ä»¶å')
    parser.add_argument('--text', type=str, help='æœç´¢åŒ…å«ç‰¹å®šæ–‡æœ¬ç‰‡æ®µçš„èŠ‚ç‚¹')
    parser.add_argument('--show-subquestions', action='store_true', help='æ˜¾ç¤ºå­é—®é¢˜åˆ†è§£ä¿¡æ¯')
    
    args = parser.parse_args()
    
    if args.text:
        # æœç´¢æ–‡æœ¬ç‰‡æ®µ
        search_text_fragment(args.question, args.text, args.top_k)
    elif args.file:
        # æœç´¢ç‰¹å®šæ–‡ä»¶
        search_specific_file(args.question, args.file, args.top_k)
    else:
        # æ˜¾ç¤ºæ‰€æœ‰æ£€ç´¢ç»“æœ
        debug_retrieval(args.question, args.top_k, args.show_subquestions)
