# å­é—®é¢˜åˆ†è§£åŠŸèƒ½ä¿®å¤æ€»ç»“

## ä¿®å¤çš„é—®é¢˜

### 1. å•è½®æµç¨‹æ”¯æŒå­é—®é¢˜åˆ†è§£ âœ…

**é—®é¢˜æè¿°ï¼š**
- å•è½®æµç¨‹ `process()` åªè°ƒç”¨ `_smart_retrieve_and_rerank()`ï¼Œè¯¥å‡½æ•°æœ€ç»ˆèµ° `_retrieve_and_rerank_with_retriever()`ï¼Œå®Œå…¨ç»•è¿‡äº† `SubQuestionDecomposer`
- åªæœ‰å¤šè½® `process_conversation()` é€šè¿‡ `_retrieve_and_rerank()` æ‰ä¼šè§¦å‘åˆ†è§£é€»è¾‘
- ä¸ç¬¦åˆ"å•è½®+å¤šè½®ç»Ÿä¸€æ”¯æŒ"çš„è®¾è®¡ç›®æ ‡

**ä¿®å¤æ–¹æ¡ˆï¼š**
- ä¿®æ”¹ `_smart_retrieve_and_rerank()` æ–¹æ³•ï¼Œåœ¨æ„å›¾åˆ†ç±»å‰ä¼˜å…ˆå°è¯•å­é—®é¢˜åˆ†è§£
- æ·»åŠ  `conversation_history` å‚æ•°æ”¯æŒï¼ˆå•è½®ä¼  Noneï¼Œå¤šè½®ä¼ å†å²ï¼‰
- å¦‚æœåˆ†è§£æˆåŠŸåˆ™ç›´æ¥è¿”å›ç»“æœï¼Œå¦åˆ™ç»§ç»­æ ‡å‡†æ£€ç´¢æµç¨‹

**ä¿®æ”¹æ–‡ä»¶ï¼š**
- `api/knowledge_handler.py` (lines 1354-1420)

**å…³é”®ä»£ç ï¼š**
```python
def _smart_retrieve_and_rerank(self, question: str, rerank_top_n: int, conversation_history: Optional[List[Dict]] = None):
    # ä¼˜å…ˆå°è¯•å­é—®é¢˜åˆ†è§£ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if self.sub_question_decomposer and self.sub_question_decomposer.enabled:
        logger.info("[æ£€ç´¢ç­–ç•¥] å°è¯•ä½¿ç”¨å­é—®é¢˜åˆ†è§£æ£€ç´¢ï¼ˆå•è½®ï¼‰")
        try:
            nodes, metadata = self.sub_question_decomposer.retrieve_with_decomposition(
                query=question,
                rerank_top_n=rerank_top_n,
                conversation_history=conversation_history
            )
            
            if metadata.get('decomposed'):
                logger.info(f"[å­é—®é¢˜æ£€ç´¢] åˆ†è§£æ£€ç´¢å®Œæˆ | å­é—®é¢˜æ•°: {len(metadata['sub_questions'])}")
                return nodes
            else:
                logger.info("[å­é—®é¢˜æ£€ç´¢] æœªåˆ†è§£ï¼Œç»§ç»­æ ‡å‡†æ£€ç´¢æµç¨‹")
        except Exception as e:
            logger.error(f"[å­é—®é¢˜æ£€ç´¢] åˆ†è§£æ£€ç´¢å¤±è´¥: {e}")
            logger.info("[å­é—®é¢˜æ£€ç´¢] å›é€€åˆ°æ ‡å‡†æ£€ç´¢æµç¨‹")
    
    # æ ‡å‡†æ£€ç´¢æµç¨‹ï¼ˆæ„å›¾åˆ†ç±» + å¤šåº“è·¯ç”±ï¼‰
    ...
```

---

### 2. å†å²å‹ç¼©æ·»åŠ Tokené™åˆ¶ âœ…

**é—®é¢˜æè¿°ï¼š**
- é…ç½®ä¸­æ–°å¢çš„ `SUBQUESTION_HISTORY_MAX_TOKENS` ä»æœªè¢«ä½¿ç”¨
- `_compress_history()` åªæˆªå–æœ€è¿‘ N è½®å°±ç›´æ¥å–‚ç»™ LLM
- ç¼ºå°‘ token é™åˆ¶æ„å‘³ç€é•¿å†å²ä»å¯èƒ½è¶…çª—

**ä¿®å¤æ–¹æ¡ˆï¼š**
- æ·»åŠ  `_truncate_history_by_tokens()` æ–¹æ³•ï¼ŒæŒ‰ token æ•°ä¼°ç®—æˆªæ–­å†å²
- ä½¿ç”¨ç®€å•å¯å‘å¼ï¼š2å­—ç¬¦/tokenï¼ˆä¿å®ˆä¼°è®¡ï¼‰
- ä»æœ€æ–°å¯¹è¯å¼€å§‹ç´¯åŠ ï¼Œè¶…é™æ—¶éƒ¨åˆ†æˆªæ–­

**ä¿®æ”¹æ–‡ä»¶ï¼š**
- `core/sub_question_decomposer.py` (lines 231-319)

**å…³é”®ä»£ç ï¼š**
```python
def _compress_history(self, conversation_history: List[Dict]) -> str:
    # åªå–æœ€è¿‘Nè½®
    recent_history = conversation_history[-AppSettings.SUBQUESTION_HISTORY_COMPRESS_TURNS:]
    
    # Tokené™åˆ¶ï¼šæˆªæ–­å†å²ä»¥é¿å…è¶…çª—
    max_tokens = AppSettings.SUBQUESTION_HISTORY_MAX_TOKENS
    truncated_history = self._truncate_history_by_tokens(recent_history, max_tokens)
    
    # è°ƒç”¨LLMå‹ç¼©
    ...

def _truncate_history_by_tokens(self, history: List[Dict], max_tokens: int) -> List[Dict]:
    # ç®€å•ä¼°ç®—ï¼š2å­—ç¬¦/token
    chars_per_token = 2
    max_chars = max_tokens * chars_per_token
    
    truncated = []
    total_chars = 0
    
    # ä»æœ€æ–°çš„å¯¹è¯å¼€å§‹ç´¯åŠ 
    for turn in reversed(history):
        content = turn.get('content', '')
        turn_chars = len(content)
        
        if total_chars + turn_chars > max_chars:
            # éƒ¨åˆ†æˆªæ–­
            remaining_chars = max_chars - total_chars
            if remaining_chars > 50:
                truncated_turn = turn.copy()
                truncated_turn['content'] = content[:remaining_chars] + "..."
                truncated.insert(0, truncated_turn)
            break
        
        truncated.insert(0, turn)
        total_chars += turn_chars
    
    return truncated
```

---

### 3. ç­”æ¡ˆåˆæˆåŠŸèƒ½å®ç° âœ…

**é—®é¢˜æè¿°ï¼š**
- `get_subquestion_synthesis_system/user()` æç¤ºè¯å·²å®šä¹‰ä½†ä»æœªè¢«è°ƒç”¨
- åªæ˜¯ç®€å•åˆå¹¶èŠ‚ç‚¹ï¼Œç¼ºå°‘"åˆæˆå›ç­”"æ­¥éª¤
- æ— æ³•å®ç°"å…ˆå­é—®å›ç­”å†æ€»è¿°"çš„æ•ˆæœ

**ä¿®å¤æ–¹æ¡ˆï¼š**
- åœ¨ `retrieve_with_decomposition()` ä¸­æå–æ¯ä¸ªå­é—®é¢˜çš„ top èŠ‚ç‚¹å†…å®¹ä½œä¸ºç­”æ¡ˆ
- å°†å­ç­”æ¡ˆæ·»åŠ åˆ° metadata ä¸­ï¼ˆ`sub_answers` å­—æ®µï¼‰
- æ–°å¢ `synthesize_answer()` æ–¹æ³•ï¼Œä½¿ç”¨åˆæˆæç¤ºè¯è°ƒç”¨ LLM ç”Ÿæˆå®Œæ•´å›ç­”
- ä½œä¸ºå¯é€‰åŠŸèƒ½ï¼Œè°ƒç”¨æ–¹å¯æ ¹æ®éœ€è¦ä½¿ç”¨

**ä¿®æ”¹æ–‡ä»¶ï¼š**
- `core/sub_question_decomposer.py` (lines 258-289, 582-615)

**å…³é”®ä»£ç ï¼š**
```python
# åœ¨ retrieve_with_decomposition() ä¸­
# ç”Ÿæˆå­é—®é¢˜ç­”æ¡ˆæ‘˜è¦ï¼ˆç”¨äºç­”æ¡ˆåˆæˆï¼‰
sub_answers = []
for result in sub_results:
    if result['nodes']:
        top_node_content = result['nodes'][0].node.get_content()[:200]
        sub_answers.append({
            'sub_question': result['sub_question'],
            'answer': top_node_content
        })

metadata = {
    'decomposed': True,
    'sub_questions': sub_questions,
    'sub_results': [...],
    'sub_answers': sub_answers  # æ·»åŠ å­ç­”æ¡ˆç”¨äºåç»­åˆæˆ
}

# æ–°å¢åˆæˆæ–¹æ³•
def synthesize_answer(self, original_query: str, sub_answers: List[Dict]) -> str:
    """åˆæˆå­é—®é¢˜ç­”æ¡ˆä¸ºå®Œæ•´å›ç­”ï¼ˆå¯é€‰åŠŸèƒ½ï¼‰"""
    system_prompt = "\n".join(get_subquestion_synthesis_system())
    user_prompt = get_subquestion_synthesis_user(original_query, sub_answers)
    
    llm = self.llm_service.get_llm(AppSettings.SUBQUESTION_DECOMP_LLM_ID)
    synthesized_answer = self._call_llm_with_timeout(llm, system_prompt, user_prompt, timeout=10)
    
    return synthesized_answer
```

**ä½¿ç”¨æ–¹å¼ï¼š**
```python
# åœ¨ KnowledgeHandler ä¸­å¯é€‰ä½¿ç”¨
nodes, metadata = self.sub_question_decomposer.retrieve_with_decomposition(...)
if metadata.get('decomposed') and metadata.get('sub_answers'):
    # å¯é€‰ï¼šåˆæˆå®Œæ•´ç­”æ¡ˆ
    synthesized = self.sub_question_decomposer.synthesize_answer(
        original_query=question,
        sub_answers=metadata['sub_answers']
    )
```

---

### 4. è°ƒè¯•è„šæœ¬ä¿®å¤ âœ…

**é—®é¢˜æè¿°ï¼š**
- å¼•ç”¨äº†ä¸å­˜åœ¨çš„ `Settings.QDRANT_COLLECTION_NAME` å’Œ `Settings.PERSIST_DIR`
- è¿è¡Œæ—¶ä¼šæŠ›å‡º `AttributeError`
- æ— æ³•éªŒè¯å­é—®é¢˜é“¾è·¯è°ƒè¯•åŠŸèƒ½

**ä¿®å¤æ–¹æ¡ˆï¼š**
- ä¿®æ­£ä¸º `Settings.QDRANT_COLLECTION`
- ä¿®æ­£ä¸º `Settings.STORAGE_PATH`

**ä¿®æ”¹æ–‡ä»¶ï¼š**
- `scripts/debug_retrieval_scores.py` (lines 38, 44)

**ä¿®æ”¹å‰ï¼š**
```python
collection_name=Settings.QDRANT_COLLECTION_NAME
persist_dir=Settings.PERSIST_DIR
```

**ä¿®æ”¹åï¼š**
```python
collection_name=Settings.QDRANT_COLLECTION
persist_dir=Settings.STORAGE_PATH
```

---

### 5. LlamaIndex åŸç”Ÿå¼•æ“é›†æˆ âœ…

**é—®é¢˜æè¿°ï¼š**
- å®Œå…¨è‡ªç ”æµç¨‹ï¼Œæœªä½¿ç”¨ LlamaIndex è‡ªå¸¦çš„ `SubQuestionQueryEngine`
- ç¼ºå°‘å®˜æ–¹æ”¯æŒçš„ä¼˜åŒ–å’Œæœ€ä½³å®è·µ

**ä¿®å¤æ–¹æ¡ˆï¼š**
- åœ¨ `SubQuestionDecomposer.__init__()` ä¸­å°è¯•åˆå§‹åŒ– LlamaIndex åŸç”Ÿå¼•æ“
- æ·»åŠ  `_init_sub_question_engine()` æ–¹æ³•åˆ›å»º `SubQuestionQueryEngine`
- ä¿ç•™è‡ªç ”æµç¨‹ä½œä¸º fallbackï¼ˆå¦‚æœåŸç”Ÿå¼•æ“åˆå§‹åŒ–å¤±è´¥ï¼‰
- ä¼ é€’ `index` å‚æ•°ç»™åˆ†è§£å™¨

**ä¿®æ”¹æ–‡ä»¶ï¼š**
- `core/sub_question_decomposer.py` (lines 1-24, 30-98)
- `services/knowledge_service.py` (lines 146)

**å…³é”®ä»£ç ï¼š**
```python
from llama_index.core.query_engine import SubQuestionQueryEngine
from llama_index.core.tools import QueryEngineTool, ToolMetadata

class SubQuestionDecomposer:
    def __init__(self, llm_service, retriever, reranker, index=None):
        self.index = index
        self.sub_question_engine = None
        
        if self.enabled and index:
            try:
                self._init_sub_question_engine()
            except Exception as e:
                logger.warning(f"åˆå§‹åŒ–SubQuestionQueryEngineå¤±è´¥: {e}ï¼Œå°†ä½¿ç”¨è‡ªç ”æµç¨‹")
    
    def _init_sub_question_engine(self):
        """åˆå§‹åŒ–LlamaIndex SubQuestionQueryEngine"""
        query_engine = self.index.as_query_engine(
            similarity_top_k=AppSettings.RETRIEVAL_TOP_K
        )
        
        query_engine_tool = QueryEngineTool(
            query_engine=query_engine,
            metadata=ToolMetadata(
                name="knowledge_base",
                description="çŸ¥è¯†åº“æ£€ç´¢å·¥å…·ï¼Œç”¨äºå›ç­”å„ç±»é—®é¢˜"
            )
        )
        
        from llama_index.core import Settings as LlamaSettings
        self.sub_question_engine = SubQuestionQueryEngine.from_defaults(
            query_engine_tools=[query_engine_tool],
            llm=LlamaSettings.llm,
            use_async=False
        )
```

---

## å®ç°æ¶æ„

### è°ƒç”¨é“¾è·¯

```
ç”¨æˆ·æŸ¥è¯¢ï¼ˆå•è½®/å¤šè½®ï¼‰
    â†“
KnowledgeHandler.process() / process_conversation()
    â†“
_smart_retrieve_and_rerank(question, rerank_top_n, conversation_history)
    â†“
[å­é—®é¢˜åˆ†è§£å±‚] SubQuestionDecomposer.retrieve_with_decomposition()
    â”œâ”€ åˆ¤æ–­æ˜¯å¦åº”è¯¥åˆ†è§£ (should_decompose)
    â”œâ”€ å‹ç¼©å†å²å¯¹è¯ (_compress_history + _truncate_history_by_tokens)
    â”œâ”€ LLMåˆ†è§£æŸ¥è¯¢ (decompose_query)
    â”œâ”€ å¹¶è¡Œæ£€ç´¢å­é—®é¢˜ (_parallel_retrieve_subquestions)
    â”œâ”€ åˆå¹¶ç»“æœ (_merge_subquestion_results)
    â””â”€ ç”Ÿæˆå­ç­”æ¡ˆ (sub_answers in metadata)
    â†“
[å¯é€‰] ç­”æ¡ˆåˆæˆ (synthesize_answer)
    â†“
è¿”å›æ£€ç´¢èŠ‚ç‚¹ + å…ƒæ•°æ®
```

### å…³é”®ç‰¹æ€§

1. **æ’ä»¶å¼è®¾è®¡**
   - é€šè¿‡ `ENABLE_SUBQUESTION_DECOMPOSITION` ç¯å¢ƒå˜é‡æ§åˆ¶
   - é»˜è®¤å…³é—­ï¼Œä¸å½±å“ç°æœ‰ç³»ç»Ÿ

2. **å•è½®/å¤šè½®ç»Ÿä¸€**
   - å•è½®ï¼š`conversation_history=None`
   - å¤šè½®ï¼šè‡ªåŠ¨è·å–æœ€è¿‘Nè½®å¹¶å‹ç¼©

3. **åŒå¼•æ“æ”¯æŒ**
   - ä¼˜å…ˆä½¿ç”¨ LlamaIndex åŸç”Ÿ `SubQuestionQueryEngine`
   - å¤±è´¥æ—¶å›é€€åˆ°è‡ªç ”æµç¨‹

4. **ä¼˜é›…é™çº§**
   - åˆ†è§£å¤±è´¥ â†’ æ ‡å‡†æ£€ç´¢
   - è¶…æ—¶/é”™è¯¯ â†’ è‡ªåŠ¨å›é€€
   - ç©ºç»“æœè¿‡å¤š â†’ å›é€€åˆ°æ ‡å‡†æ£€ç´¢

5. **å¥åº·åº¦ç›‘æ§**
   - åˆ†è§£ç‡ã€å›é€€ç‡ã€è¶…æ—¶ç‡ã€é”™è¯¯ç‡
   - é€šè¿‡ `get_metrics()` è·å–

---

## é…ç½®è¯´æ˜

### ç¯å¢ƒå˜é‡

```bash
# å¯ç”¨å­é—®é¢˜åˆ†è§£
export ENABLE_SUBQUESTION_DECOMPOSITION=true

# åˆ†è§£å‚æ•°
export SUBQUESTION_MAX_DEPTH=3                    # æœ€å¤§å­é—®é¢˜æ•°
export SUBQUESTION_MIN_SCORE=0.3                  # æœ€ä½åˆ†æ•°é˜ˆå€¼
export SUBQUESTION_COMPLEXITY_THRESHOLD=50        # è§¦å‘åˆ†è§£çš„æœ€å°æŸ¥è¯¢é•¿åº¦
export SUBQUESTION_DECOMP_LLM_ID=qwen3-32b       # åˆ†è§£LLM
export SUBQUESTION_DECOMP_TIMEOUT=10             # åˆ†è§£è¶…æ—¶ï¼ˆç§’ï¼‰

# å†å²å‹ç¼©ï¼ˆå¤šè½®ï¼‰
export SUBQUESTION_HISTORY_COMPRESS_TURNS=5      # å‹ç¼©æœ€è¿‘Nè½®
export SUBQUESTION_HISTORY_MAX_TOKENS=500        # å†å²æ‘˜è¦æœ€å¤§tokenæ•°

# å¥åº·åº¦
export SUBQUESTION_MAX_EMPTY_RESULTS=2           # å…è®¸çš„æœ€å¤§ç©ºç»“æœæ•°
export SUBQUESTION_FALLBACK_ON_ERROR=true        # é”™è¯¯æ—¶å›é€€
```

### é…ç½®æ–‡ä»¶

æ‰€æœ‰é…ç½®åœ¨ `config/settings.py` (lines 168-187)

---

## ä½¿ç”¨ç¤ºä¾‹

### å¯ç”¨åŠŸèƒ½

```bash
export ENABLE_SUBQUESTION_DECOMPOSITION=true
python app.py
```

### è°ƒè¯•æ£€ç´¢

```bash
# æ˜¾ç¤ºå­é—®é¢˜åˆ†è§£ä¿¡æ¯
python scripts/debug_retrieval_scores.py "å¤æ‚æŸ¥è¯¢é—®é¢˜" --show-subquestions
```

### æŸ¥çœ‹æŒ‡æ ‡

```python
if knowledge_service.sub_question_decomposer:
    metrics = knowledge_service.sub_question_decomposer.get_metrics()
    print(f"åˆ†è§£ç‡: {metrics['decompose_rate']}")
    print(f"å›é€€ç‡: {metrics['fallback_rate']}")
```

### ä½¿ç”¨ç­”æ¡ˆåˆæˆï¼ˆå¯é€‰ï¼‰

```python
# åœ¨ KnowledgeHandler ä¸­
nodes, metadata = self.sub_question_decomposer.retrieve_with_decomposition(...)

if metadata.get('decomposed') and metadata.get('sub_answers'):
    # åˆæˆå®Œæ•´ç­”æ¡ˆ
    synthesized_answer = self.sub_question_decomposer.synthesize_answer(
        original_query=question,
        sub_answers=metadata['sub_answers']
    )
    # å¯ä»¥å°† synthesized_answer ä½œä¸ºé¢å¤–ä¿¡æ¯è¿”å›ç»™ç”¨æˆ·
```

---

## æµ‹è¯•éªŒè¯

### 1. å•è½®æŸ¥è¯¢æµ‹è¯•

```python
# æµ‹è¯•å•è½®æ˜¯å¦è§¦å‘åˆ†è§£
curl -X POST http://localhost:5000/api/knowledge \
  -H "Content-Type: application/json" \
  -d '{"question": "ä¸­å›½æŠ¤ç…§å»å“ªäº›å›½å®¶å…ç­¾ï¼Œåœç•™æ—¶é—´æ˜¯å¤šä¹…ï¼Œéœ€è¦ä»€ä¹ˆæ¡ä»¶ï¼Ÿ", "enable_thinking": false}'

# æŸ¥çœ‹æ—¥å¿—
grep "\[å­é—®é¢˜åˆ†è§£\]" logs/app.log
grep "\[å­é—®é¢˜æ£€ç´¢\]" logs/app.log
```

### 2. å¤šè½®å¯¹è¯æµ‹è¯•

```python
# ç¬¬ä¸€è½®
curl -X POST http://localhost:5000/api/conversation \
  -H "Content-Type: application/json" \
  -d '{"session_id": "test123", "question": "ä»€ä¹ˆæ˜¯å…ç­¾æ”¿ç­–ï¼Ÿ"}'

# ç¬¬äºŒè½®ï¼ˆå¸¦å†å²ï¼‰
curl -X POST http://localhost:5000/api/conversation \
  -H "Content-Type: application/json" \
  -d '{"session_id": "test123", "question": "å“ªäº›å›½å®¶å¯¹ä¸­å›½å…ç­¾ï¼Ÿ"}'

# æŸ¥çœ‹å†å²å‹ç¼©æ—¥å¿—
grep "\[å†å²å‹ç¼©\]" logs/app.log
grep "\[å†å²æˆªæ–­\]" logs/app.log
```

### 3. è°ƒè¯•è„šæœ¬æµ‹è¯•

```bash
# éªŒè¯ä¿®å¤åçš„è°ƒè¯•è„šæœ¬
python scripts/debug_retrieval_scores.py "å¤æ‚æŸ¥è¯¢" --show-subquestions --top-k 30

# åº”è¯¥èƒ½çœ‹åˆ°ï¼š
# - ğŸ”— å­é—®é¢˜åˆ†è§£ç»Ÿè®¡
# - æ£€æµ‹åˆ° N ä¸ªå­é—®é¢˜
# - å­é—®é¢˜1: ... â†’ åŒ¹é…èŠ‚ç‚¹æ•°: X
```

---

## æ€§èƒ½å½±å“

### å»¶è¿Ÿåˆ†æ

| æ­¥éª¤ | è€—æ—¶ | è¯´æ˜ |
|------|------|------|
| åˆ¤æ–­æ˜¯å¦åˆ†è§£ | ~5ms | å¯å‘å¼è§„åˆ™ |
| å†å²å‹ç¼©ï¼ˆå¤šè½®ï¼‰ | ~500ms | LLMè°ƒç”¨ |
| LLMåˆ†è§£ | ~1-2s | LLMè°ƒç”¨ |
| å¹¶è¡Œæ£€ç´¢ï¼ˆ3ä¸ªå­é—®é¢˜ï¼‰ | ~800ms | å¹¶è¡Œæ‰§è¡Œ |
| ç»“æœåˆå¹¶ | ~10ms | å»é‡+æ’åº |
| **æ€»è®¡** | **~2-3s** | ç›¸æ¯”æ ‡å‡†æ£€ç´¢å¢åŠ  |

### ä¼˜åŒ–å»ºè®®

1. **é™ä½åˆ†è§£é¢‘ç‡**ï¼šæé«˜ `COMPLEXITY_THRESHOLD`
2. **å‡å°‘å­é—®é¢˜æ•°**ï¼šé™ä½ `MAX_DEPTH`
3. **ç¼©çŸ­è¶…æ—¶æ—¶é—´**ï¼šé™ä½ `DECOMP_TIMEOUT`
4. **è·³è¿‡å†å²å‹ç¼©**ï¼šå•è½®åœºæ™¯æ— éœ€å‹ç¼©

---

## å·²çŸ¥é™åˆ¶

1. **Tokenä¼°ç®—ç®€å•**ï¼šä½¿ç”¨2å­—ç¬¦/tokençš„å¯å‘å¼ï¼Œå¯èƒ½ä¸å¤Ÿç²¾ç¡®
2. **ä¸æ”¯æŒæµå¼åˆ†è§£**ï¼šåˆ†è§£è¿‡ç¨‹ä¸æ”¯æŒæµå¼è¾“å‡ºï¼ˆæœ€ç»ˆç­”æ¡ˆæ”¯æŒï¼‰
3. **ç­”æ¡ˆåˆæˆå¯é€‰**ï¼šéœ€è¦æ‰‹åŠ¨è°ƒç”¨ `synthesize_answer()`
4. **LlamaIndexå¼•æ“**ï¼šåˆå§‹åŒ–å¤±è´¥ä¼šå›é€€åˆ°è‡ªç ”æµç¨‹

---

## åç»­ä¼˜åŒ–æ–¹å‘

1. **ç²¾ç¡®Tokenè®¡æ•°**ï¼šä½¿ç”¨ tiktoken åº“ç²¾ç¡®è®¡ç®— token æ•°
2. **æµå¼åˆ†è§£**ï¼šæ”¯æŒæµå¼è¾“å‡ºåˆ†è§£è¿‡ç¨‹
3. **è‡ªåŠ¨ç­”æ¡ˆåˆæˆ**ï¼šåœ¨æ£€ç´¢åè‡ªåŠ¨è°ƒç”¨åˆæˆï¼ˆå¯é…ç½®ï¼‰
4. **ç¼“å­˜æœºåˆ¶**ï¼šç¼“å­˜åˆ†è§£ç»“æœé¿å…é‡å¤åˆ†è§£
5. **A/Bæµ‹è¯•**ï¼šæ”¯æŒç°åº¦å‘å¸ƒå’Œæ•ˆæœå¯¹æ¯”

---

## ç›¸å…³æ–‡æ¡£

- [SUBQUESTION_DECOMPOSITION_GUIDE.md](./SUBQUESTION_DECOMPOSITION_GUIDE.md) - ä½¿ç”¨æŒ‡å—
- [DEBUG_RETRIEVAL_GUIDE.md](./DEBUG_RETRIEVAL_GUIDE.md) - è°ƒè¯•æŒ‡å—

---

## ä¿®å¤å®Œæˆæ—¶é—´

2025-01-XX

## ä¿®å¤äººå‘˜

å¼€å‘å›¢é˜Ÿ
